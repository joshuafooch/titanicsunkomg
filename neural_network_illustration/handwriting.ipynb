{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6bcab69-d4a7-4001-84f8-a953d4483478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from IPython.display import Image, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b0be95-7174-4fef-b3b9-2bc4d4a4113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 5000 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 10:29:56.460332: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-05-11 10:29:56.460415: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-05-11 10:29:56.460421: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-05-11 10:29:56.460524: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-11 10:29:56.460560: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "training_data, validation_data, test_data = tfds.load('MNIST', split=['train', 'test[:50%]', 'test[50%:]'], as_supervised=True)\n",
    "print(len(training_data), len(validation_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d7fde7a-3fcb-43d0-bd9a-6506b08f4d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 10:34:40.970065: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise the dataset\n",
    "example_data = iter(training_data.take(1)).next()\n",
    "plt.imshow(example_data[0])\n",
    "print(example_data[1])\n",
    "print(example_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac0358c-2617-4a80-b183-2b87cd0c38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return (image, label)\n",
    "\n",
    "training_data = training_data.map(preprocess)\n",
    "validation_data = validation_data.map(preprocess)\n",
    "test_data = test_data.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6458f44e-19b8-4783-91d6-ba4fb1bab4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle dataset\n",
    "training_data = training_data.shuffle(60000).batch(128)\n",
    "validation_data = validation_data.batch(128)\n",
    "test_data = test_data.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa441596-7b04-4431-b905-5fda37db46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8070 (31.52 KB)\n",
      "Trainable params: 8070 (31.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simple Dense NN using Functional API for outputs of activations\n",
    "inputs = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "flattened = tf.keras.layers.Flatten()(inputs)\n",
    "activations_1 = tf.keras.layers.Dense(units=10, activation='sigmoid')(flattened)\n",
    "activations_2 = tf.keras.layers.Dense(units=10, activation='sigmoid')(activations_1)\n",
    "predictions = tf.keras.layers.Dense(units=10, activation='softmax')(activations_2)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[activations_1, activations_2, predictions])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26cf6944-27a5-4d32-9bef-84dc8738658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f4836b4-d5aa-4620-9bdc-418da0b0a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0633 - dense_11_loss: 0.3428 - dense_12_loss: 0.3590 - dense_13_loss: 0.3615 - dense_11_accuracy: 0.9102 - dense_12_accuracy: 0.9011 - dense_13_accuracy: 0.8975 - val_loss: 1.1048 - val_dense_11_loss: 0.3552 - val_dense_12_loss: 0.3713 - val_dense_13_loss: 0.3783 - val_dense_11_accuracy: 0.9088 - val_dense_12_accuracy: 0.8950 - val_dense_13_accuracy: 0.8954\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0519 - dense_11_loss: 0.3402 - dense_12_loss: 0.3548 - dense_13_loss: 0.3569 - dense_11_accuracy: 0.9108 - dense_12_accuracy: 0.9025 - dense_13_accuracy: 0.9002 - val_loss: 1.1023 - val_dense_11_loss: 0.3553 - val_dense_12_loss: 0.3701 - val_dense_13_loss: 0.3769 - val_dense_11_accuracy: 0.9084 - val_dense_12_accuracy: 0.8960 - val_dense_13_accuracy: 0.8968\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0431 - dense_11_loss: 0.3393 - dense_12_loss: 0.3508 - dense_13_loss: 0.3529 - dense_11_accuracy: 0.9112 - dense_12_accuracy: 0.9036 - dense_13_accuracy: 0.9007 - val_loss: 1.0921 - val_dense_11_loss: 0.3525 - val_dense_12_loss: 0.3683 - val_dense_13_loss: 0.3713 - val_dense_11_accuracy: 0.9090 - val_dense_12_accuracy: 0.8974 - val_dense_13_accuracy: 0.8960\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0337 - dense_11_loss: 0.3368 - dense_12_loss: 0.3478 - dense_13_loss: 0.3491 - dense_11_accuracy: 0.9124 - dense_12_accuracy: 0.9042 - dense_13_accuracy: 0.9018 - val_loss: 1.0893 - val_dense_11_loss: 0.3526 - val_dense_12_loss: 0.3664 - val_dense_13_loss: 0.3702 - val_dense_11_accuracy: 0.9108 - val_dense_12_accuracy: 0.8970 - val_dense_13_accuracy: 0.8942\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0251 - dense_11_loss: 0.3362 - dense_12_loss: 0.3438 - dense_13_loss: 0.3451 - dense_11_accuracy: 0.9121 - dense_12_accuracy: 0.9051 - dense_13_accuracy: 0.9023 - val_loss: 1.0752 - val_dense_11_loss: 0.3501 - val_dense_12_loss: 0.3580 - val_dense_13_loss: 0.3672 - val_dense_11_accuracy: 0.9110 - val_dense_12_accuracy: 0.8998 - val_dense_13_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0164 - dense_11_loss: 0.3340 - dense_12_loss: 0.3407 - dense_13_loss: 0.3417 - dense_11_accuracy: 0.9125 - dense_12_accuracy: 0.9064 - dense_13_accuracy: 0.9038 - val_loss: 1.0754 - val_dense_11_loss: 0.3469 - val_dense_12_loss: 0.3599 - val_dense_13_loss: 0.3686 - val_dense_11_accuracy: 0.9126 - val_dense_12_accuracy: 0.8994 - val_dense_13_accuracy: 0.8968\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0088 - dense_11_loss: 0.3316 - dense_12_loss: 0.3378 - dense_13_loss: 0.3394 - dense_11_accuracy: 0.9130 - dense_12_accuracy: 0.9062 - dense_13_accuracy: 0.9044 - val_loss: 1.0724 - val_dense_11_loss: 0.3539 - val_dense_12_loss: 0.3565 - val_dense_13_loss: 0.3621 - val_dense_11_accuracy: 0.9088 - val_dense_12_accuracy: 0.9002 - val_dense_13_accuracy: 0.8992\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 1.0010 - dense_11_loss: 0.3312 - dense_12_loss: 0.3347 - dense_13_loss: 0.3351 - dense_11_accuracy: 0.9132 - dense_12_accuracy: 0.9082 - dense_13_accuracy: 0.9054 - val_loss: 1.0700 - val_dense_11_loss: 0.3497 - val_dense_12_loss: 0.3557 - val_dense_13_loss: 0.3647 - val_dense_11_accuracy: 0.9122 - val_dense_12_accuracy: 0.9010 - val_dense_13_accuracy: 0.8996\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.9938 - dense_11_loss: 0.3294 - dense_12_loss: 0.3321 - dense_13_loss: 0.3323 - dense_11_accuracy: 0.9140 - dense_12_accuracy: 0.9088 - dense_13_accuracy: 0.9062 - val_loss: 1.0567 - val_dense_11_loss: 0.3496 - val_dense_12_loss: 0.3496 - val_dense_13_loss: 0.3575 - val_dense_11_accuracy: 0.9112 - val_dense_12_accuracy: 0.9032 - val_dense_13_accuracy: 0.9020\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.9875 - dense_11_loss: 0.3281 - dense_12_loss: 0.3295 - dense_13_loss: 0.3299 - dense_11_accuracy: 0.9150 - dense_12_accuracy: 0.9093 - dense_13_accuracy: 0.9065 - val_loss: 1.0581 - val_dense_11_loss: 0.3473 - val_dense_12_loss: 0.3499 - val_dense_13_loss: 0.3610 - val_dense_11_accuracy: 0.9130 - val_dense_12_accuracy: 0.9002 - val_dense_13_accuracy: 0.9002\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(training_data, validation_data = validation_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80a8ffdd-8c3c-4461-84ac-458a9edcaa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 1.0283 - dense_11_loss: 0.3264 - dense_12_loss: 0.3526 - dense_13_loss: 0.3492 - dense_11_accuracy: 0.9130 - dense_12_accuracy: 0.9028 - dense_13_accuracy: 0.8976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.028257966041565,\n",
       " 0.32641512155532837,\n",
       " 0.3526128828525543,\n",
       " 0.3492298722267151,\n",
       " 0.9129999876022339,\n",
       " 0.9028000235557556,\n",
       " 0.897599995136261]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d7d914e-951c-4062-90bf-8a32b6c0d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshua/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('handwriting.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c055e2d-4ea1-49db-a324-cdfa47cae745",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter \\\n",
    "--input_format=keras \\\n",
    "--output_format=tfjs_layers_model \\\n",
    "handwriting.h5 \\\n",
    "./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b653d5-464c-4807-8172-ac32e38e5c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "venv-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
